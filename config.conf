# [DEFAULT]
# random_policy: The agent chooses a random action
# visualize: The window is showed
# skip_log: The log won't be written
# progress_interval: Per how many steps to print the progress
# agent_speed: Set the agent's moving speed
# step_max: Max step of one episode
# description: A name of the experiment
# save_interval: Per how many steps to save the model
# skip_save: The model won’t be saved
# load: Load the networks’ parameters from the entire path. Format: (environment)/(description)/(step)
# load_inverse: Load feature extractor inverse network parameters from the specific file. Format: (environment)/(description)/(step)
# load_predictor: Load predictor network parameters from the specific file. Format: (environment)/(description)/(step)
# load_controller: Load controller network parameters from the specific file. Format: (environment)/(description)/(step)
# device: The program uses the cpu in purpose
#
# [hyperparameter]
# feature_extractor_inverse_lr
# predictor_lr
# controller_lr
# hidden_state_size
# feature_size
# predictor_RNN_num_layers
# feature_extractor_layerwise_shape = 64,128
# inverse_network_layerwise_shape = 128

[DEFAULT]
description = default
load = None
load_inverse = None
load_predictor = None
load_controller = None
device = cpu
visualize = False
skip_log = False
skip_save = False
save_interval = 50000

step_max = 5000
progress_interval = 1000
agent_speed = 10
random_policy = True

feature_extractor_inverse_lr = 1e-4
predictor_lr = 1e-4
controller_lr = 1e-4
hidden_state_size = 128
feature_size = 128
predictor_RNN_num_layers = 2
feature_extractor_layerwise_shape = 64,128
inverse_network_layerwise_shape = 128